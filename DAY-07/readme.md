# ðŸ§¬ Day 07: Support Vector Machines (SVM) â€“ Breast Cancer Classification

## ðŸ“Œ Task Objective
To implement and evaluate **Support Vector Machine (SVM)** classifiers for identifying whether a tumor is **malignant** or **benign** using the **Breast Cancer dataset**.

---

## ðŸ—‚ï¸ Dataset Overview

- **Dataset:** breast-cancer.csv
- **Rows:** 569
- **Target Column:** `diagnosis`  
  - `M` = Malignant (1)  
  - `B` = Benign (0)
- **Features:** 30 numerical attributes
- **Dropped Column:** `id` (non-informative)

---

## ðŸ› ï¸ Tools & Libraries

- `pandas`, `numpy` â€“ Data handling  
- `matplotlib`, `seaborn` â€“ Visualization  
- `scikit-learn` â€“ SVM modeling, preprocessing, tuning, evaluation  
- `Google Colab` â€“ Development platform

---

## ðŸ” Workflow Summary

### âœ… Step 1: Preprocessing
- Dropped `id` column
- Encoded `diagnosis` as binary (M = 1, B = 0)
- Normalized features using `StandardScaler`

### âœ… Step 2: Model Training
- Split data (80% train / 20% test)
- Trained two models:
  - `SVC(kernel="linear")`
  - `SVC(kernel="rbf")`

### âœ… Step 3: Hyperparameter Tuning
- Tuned `C` and `gamma` using `GridSearchCV` with 5-fold cross-validation
- Selected best parameters for `RBF` kernel

### âœ… Step 4: Model Evaluation
- Calculated:
  - Accuracy
  - Confusion Matrix
  - Classification Report
- Used `ConfusionMatrixDisplay` to visualize predictions
- Evaluated final model with **cross-validation**

---

## âœ… Results

| Model              | Accuracy |
|-------------------|----------|
| Linear SVM         | ~97%     |
| RBF SVM (default)  | ~98%     |
| RBF SVM (tuned)    | ~99%     |
| Cross-Validation   | ~98â€“99%  |

> The **tuned SVM with RBF kernel** outperformed the linear model with the best generalization performance.

---

## ðŸ“Š Visuals Included

- âœ… Confusion Matrix (Seaborn & sklearn display)  
- âœ… Classification Report for both kernels  
- âœ… GridSearchCV tuning report  

---

## ðŸ§  Learnings

- **SVMs** are highly effective for binary classification
- **RBF kernels** capture non-linear patterns better than linear kernels
- **Feature scaling** is essential for SVM performance
- **Hyperparameter tuning** significantly boosts accuracy
- **Cross-validation** ensures model stability

---

## ðŸš€ Next Step
Apply SVMs to multi-class datasets or experiment with kernels like `poly` or `sigmoid` to explore advanced capabilities.

