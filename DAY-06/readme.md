# ðŸŒ¸ Day 06: K-Nearest Neighbors (KNN) â€“ Iris Flower Classification

## ðŸ“Œ Task Objective
To implement and evaluate the **K-Nearest Neighbors (KNN)** algorithm for classifying iris flower species based on their physical characteristics.

---

## ðŸ—‚ï¸ Dataset Overview

- **Dataset:** Iris.csv
- **Rows:** 150
- **Target Column:** `Species` (Multiclass: Setosa, Versicolor, Virginica)
- **Features:**
  - `SepalLengthCm`
  - `SepalWidthCm`
  - `PetalLengthCm`
  - `PetalWidthCm`

---

## ðŸ› ï¸ Tools Used

- `pandas`, `numpy` â€“ Data handling  
- `matplotlib`, `seaborn` â€“ Visualization  
- `scikit-learn` â€“ KNN model, preprocessing, evaluation  
- `Google Colab` â€“ Development environment  

---

## ðŸ” Workflow Summary

### âœ… Step 1: Data Preparation
- Dropped unnecessary `Id` column
- Encoded `Species` into numerical format
- Normalized features using `StandardScaler`

### âœ… Step 2: Train-Test Split
- 80% training data, 20% testing data

### âœ… Step 3: Model Training
- Trained multiple `KNeighborsClassifier` models for **K = 1 to 10**
- Selected best value based on accuracy

### âœ… Step 4: Evaluation
- Calculated **accuracy**, **confusion matrix**, and **classification report**
- Plotted **confusion matrix heatmap**

### âœ… Step 5: Decision Boundary Visualization (Bonus)
- Visualized KNN decision boundary using only 2 features:  
  `PetalLengthCm` and `PetalWidthCm`  
- Used `matplotlib` and `ListedColormap` to plot 2D class regions

---

## âœ… Results

| K | Accuracy |
|---|----------|
| 3 | ~97%     |
| 5 | ~97%     |
| 7 | ~97%     |

> The model achieved **excellent performance** across all K values, especially for **K = 3â€“7**.

---

## ðŸ“Š Visuals

- âœ… Confusion Matrix Heatmap  
- âœ… Decision Boundary (2D) using Petal Features  
- âœ… Accuracy comparisons for different K values  

---

## ðŸ§  Learnings

- KNN is a **simple yet powerful** classification algorithm  
- **Scaling features** is crucial for distance-based models  
- Visualization helps in understanding **decision boundaries**  
- Model performance is **sensitive to K value** and **data distribution**

